import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import os

# Importer nos modules optimis√©s
from model import get_compiled_unet, print_model_info
from load_data import get_dataset

print("üöÄ ENTRA√éNEMENT OPTIMIS√â POUR VOTRE CONFIGURATION")
print("="*60)

# ===== CONFIGURATION SYST√àME =====
print("‚öôÔ∏è  Configuration du syst√®me...")

# Optimiser l'utilisation du CPU (important pour Intel Iris Xe)
tf.config.threading.set_intra_op_parallelism_threads(0)  # Utilise tous les c≈ìurs
tf.config.threading.set_inter_op_parallelism_threads(0)  # Parall√©lisme entre op√©rations

# V√©rifier les devices disponibles
print("üñ•Ô∏è  Devices disponibles:")
for device in tf.config.list_physical_devices():
    print(f"   - {device}")

# Optimiser la m√©moire GPU si disponible
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("‚úÖ Croissance m√©moire GPU activ√©e")
    except RuntimeError as e:
        print(f"‚ö†Ô∏è  Erreur config GPU: {e}")
else:
    print("‚ÑπÔ∏è  Pas de GPU d√©di√© d√©tect√© - utilisation CPU + Intel Iris Xe")

# ===== PARAM√àTRES D'ENTRA√éNEMENT =====
BATCH_SIZE = 8          # Optimis√© pour 16GB RAM
EPOCHS = 50             # R√©duit de 100 √† 50 pour tester plus vite
VALIDATION_SPLIT = 0.2  # 20% pour validation

print(f"üìä Param√®tres:")
print(f"   - Batch size: {BATCH_SIZE}")
print(f"   - √âpochs: {EPOCHS}")
print(f"   - Validation: {VALIDATION_SPLIT*100:.0f}%")

# ===== CHARGEMENT DES DONN√âES =====
print("\nüìÅ Chargement du dataset...")
try:
    train_ds = get_dataset(batch_size=BATCH_SIZE)
    print("‚úÖ Dataset charg√© avec succ√®s")
    
    # Calculer le nombre d'√©chantillons (approximatif)
    sample_count = 0
    for batch in train_ds.take(10):  # √âchantillon pour estimation
        sample_count += batch[0].shape[0]
    estimated_total = sample_count * 10  # Estimation grossi√®re
    print(f"üìà √âchantillons estim√©s: ~{estimated_total}")
    
except Exception as e:
    print(f"‚ùå Erreur lors du chargement: {e}")
    print("V√©rifiez que les dossiers 'dataset/CapturedImages' et 'dataset/mask' existent")
    exit(1)

# ===== CR√âATION DU MOD√àLE =====
print("\nüèóÔ∏è  Cr√©ation du mod√®le...")
model = get_compiled_unet(use_light_version=True)  # Version all√©g√©e recommand√©e

# Afficher les informations du mod√®le
print_model_info(model)

# ===== CALLBACKS INTELLIGENTS =====
print("üéõÔ∏è  Configuration des callbacks...")

# Cr√©er le dossier pour les sauvegardes
os.makedirs("checkpoints", exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

callbacks = [
    # R√©duction automatique du learning rate
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='loss',
        factor=0.5,              # Divise par 2
        patience=5,              # Attend 5 √©poques
        min_lr=1e-7,            # Learning rate minimum
        verbose=1,
        cooldown=2               # Attend 2 √©poques avant nouvelle r√©duction
    ),
    
    # Arr√™t anticip√© si pas d'am√©lioration
    tf.keras.callbacks.EarlyStopping(
        monitor='loss',
        patience=10,             # Patience plus √©lev√©e
        restore_best_weights=True,
        verbose=1,
        min_delta=0.001         # Am√©lioration minimale requise
    ),
    
    # Sauvegarde du meilleur mod√®le
    tf.keras.callbacks.ModelCheckpoint(
        f'checkpoints/best_model_{timestamp}.h5',
        monitor='loss',
        save_best_only=True,
        save_weights_only=False,
        verbose=1,
        mode='min'
    ),
    
    # Logging d√©taill√©
    tf.keras.callbacks.CSVLogger(
        f'checkpoints/training_log_{timestamp}.csv',
        separator=',',
        append=False
    ),
    
    # R√©duction progressive du learning rate (backup)
    tf.keras.callbacks.LearningRateScheduler(
        lambda epoch: 0.001 * (0.95 ** epoch),
        verbose=0
    )
]

print(f"‚úÖ {len(callbacks)} callbacks configur√©s")

# ===== ENTRA√éNEMENT =====
print("\n" + "="*60)
print("üî• D√âBUT DE L'ENTRA√éNEMENT")
print("="*60)

try:
    # Mesurer le temps d'entra√Ænement
    start_time = datetime.now()
    
    history = model.fit(
        train_ds,
        epochs=EPOCHS,
        callbacks=callbacks,
        verbose=1,                    # Affichage d√©taill√©
        workers=4,                    # Parall√©lisme pour le chargement des donn√©es
        use_multiprocessing=False,    # √âvite les probl√®mes sur certains syst√®mes
        max_queue_size=10            # Limite la queue pour √©conomiser la RAM
    )
    
    end_time = datetime.now()
    training_duration = end_time - start_time
    
    print("\n" + "="*60)
    print("‚úÖ ENTRA√éNEMENT TERMIN√â")
    print(f"‚è±Ô∏è  Dur√©e: {training_duration}")
    print(f"üìà √âpoques r√©alis√©es: {len(history.history['loss'])}")
    print("="*60)
    
except KeyboardInterrupt:
    print("\n‚ö†Ô∏è  Entra√Ænement interrompu par l'utilisateur")
    print("üíæ Sauvegarde du mod√®le actuel...")
    model.save(f"model_interrupted_{timestamp}.h5")
    
except Exception as e:
    print(f"\n‚ùå Erreur pendant l'entra√Ænement: {e}")
    print("üíæ Tentative de sauvegarde...")
    try:
        model.save(f"model_error_{timestamp}.h5")
        print("‚úÖ Mod√®le sauvegard√© malgr√© l'erreur")
    except:
        print("‚ùå Impossible de sauvegarder")

# ===== SAUVEGARDE FINALE =====
print("\nüíæ Sauvegarde du mod√®le final...")
try:
    final_model_path = f"line_segment_model_optimized_{timestamp}.h5"
    model.save(final_model_path)
    print(f"‚úÖ Mod√®le sauvegard√©: {final_model_path}")
    
    # Sauvegarde de l'historique
    np.save(f'checkpoints/history_{timestamp}.npy', history.history)
    print(f"üìä Historique sauvegard√©: checkpoints/history_{timestamp}.npy")
    
except Exception as e:
    print(f"‚ùå Erreur lors de la sauvegarde: {e}")

# ===== VISUALISATION DES R√âSULTATS =====
print("\nüìä G√©n√©ration des graphiques de performance...")

try:
    plt.style.use('default')  # Style propre
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Loss
    axes[0, 0].plot(history.history['loss'], 'b-', label='Loss', linewidth=2)
    axes[0, 0].set_title('üìâ √âvolution de la Loss', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('√âpoque')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].legend()
    
    # Accuracy
    axes[0, 1].plot(history.history['accuracy'], 'g-', label='Accuracy', linewidth=2)
    axes[0, 1].set_title('üìà √âvolution de l\'Accuracy', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('√âpoque')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].legend()
    
    # Precision
    if 'precision' in history.history:
        axes[1, 0].plot(history.history['precision'], 'r-', label='Precision', linewidth=2)
        axes[1, 0].set_title('üéØ √âvolution de la Precision', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('√âpoque')
        axes[1, 0].set_ylabel('Precision')
        axes[1, 0].grid(True, alpha=0.3)
        axes[1, 0].legend()
    
    # Recall
    if 'recall' in history.history:
        axes[1, 1].plot(history.history['recall'], 'm-', label='Recall', linewidth=2)
        axes[1, 1].set_title('üîç √âvolution du Recall', fontsize=14, fontweight='bold')
        axes[1, 1].set_xlabel('√âpoque')
        axes[1, 1].set_ylabel('Recall')
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].legend()
    
    plt.tight_layout()
    
    # Sauvegarder le graphique
    graph_path = f'checkpoints/training_curves_{timestamp}.png'
    plt.savefig(graph_path, dpi=300, bbox_inches='tight')
    print(f"üìä Graphiques sauvegard√©s: {graph_path}")
    
    plt.show()
    
except Exception as e:
    print(f"‚ö†Ô∏è  Erreur lors de la g√©n√©ration des graphiques: {e}")

# ===== R√âSUM√â FINAL =====
print("\n" + "="*60)
print("üéâ ENTRA√éNEMENT COMPL√âT√â")
print("="*60)

if 'history' in locals():
    final_loss = history.history['loss'][-1]
    final_accuracy = history.history['accuracy'][-1]
    
    print(f"üìä R√©sultats finaux:")
    print(f"   - Loss finale: {final_loss:.4f}")
    print(f"   - Accuracy finale: {final_accuracy:.4f}")
    
    if 'precision' in history.history:
        final_precision = history.history['precision'][-1]
        print(f"   - Precision finale: {final_precision:.4f}")
    
    if 'recall' in history.history:
        final_recall = history.history['recall'][-1]
        print(f"   - Recall finale: {final_recall:.4f}")

print(f"\nüéØ Prochaines √©tapes:")
print(f"   1. Testez le mod√®le avec apply_model.py")
print(f"   2. V√©rifiez les r√©sultats visuels")
print(f"   3. Ajustez les param√®tres si n√©cessaire")

print("\nüí° Conseils d'optimisation:")
print("   - Si trop lent: r√©duisez IMG_HEIGHT/WIDTH √† 96")
print("   - Si manque de RAM: r√©duisez BATCH_SIZE √† 4")
print("   - Si sous-apprentissage: augmentez EPOCHS")

print("="*60)